clip_model_load: model name:   openai/clip-vit-large-patch14-336
clip_model_load: description:  image encoder for LLaVA
clip_model_load: GGUF version: 2
clip_model_load: alignment:    32
clip_model_load: n_tensors:    377
clip_model_load: n_kv:         18
clip_model_load: ftype:        f16

clip_model_load: text_encoder:   0
clip_model_load: vision_encoder: 1
clip_model_load: llava_projector:  1
clip_model_load: model size:     595.62 MB
clip_model_load: metadata size:  0.14 MB
clip_model_load: total allocated memory: 195.95 MB

encode_image_with_clip: image encoded in  1314.36 ms by CLIP (    2.28 ms per image patch)

 In the image, there are two women wearing dresses. One woman is standing and posing for the camera, while the other woman is sitting on a white chair. Both women are wearing dresses, which can be worn in various situations, such as formal events, weddings, or special occasions. The dresses can also be worn for a daytime outing, a date, or a casual gathering with friends and family. The dresses are designed to be comfortable and stylish, making them suitable for a wide range of occasions.
